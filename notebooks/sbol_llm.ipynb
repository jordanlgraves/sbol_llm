{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Jyu6sfPR3w"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObgJmeXu03vF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM2Zfnmy88bH"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"\"\n",
        ")\n",
        "\n",
        "PDF_DIR = \"/content/drive/My Drive/Projects/Project records/Nona works\"\n",
        "fair_pdf_path = f\"{PDF_DIR}/fair_publication.pdf\"\n",
        "miriam_pdf_path = f\"{PDF_DIR}/miriam_publication.pdf\"\n",
        "\n",
        "# @st.cache_resource\n",
        "# def initialize_assistant():\n",
        "#     with open(fair_pdf_path, 'rb') as pdf_file:\n",
        "#         fair_file = client.files.create(file=pdf_file, purpose='assistants')\n",
        "\n",
        "#     with open(miriam_pdf_path, 'rb') as pdf_file:\n",
        "#         miriam_file = client.files.create(file=pdf_file, purpose='assistants')\n",
        "\n",
        "#     assistant = client.beta.assistants.create(\n",
        "#         name=\"FAIR & MIRIAM Research Assistant\",\n",
        "#         instructions=\"You are an expert on the FAIR principles and MIRIAM publications.\",\n",
        "#         model=\"gpt-3.5-turbo\",\n",
        "#         tools=[{\"type\": \"code_interpreter\"}],\n",
        "#         tool_resources={\"code_interpreter\": {\"file_ids\": [fair_file.id, miriam_file.id]}}\n",
        "#     )\n",
        "#     return assistant\n",
        "\n",
        "def main():\n",
        "    st.title(\"FAIR & MIRIAM Assistant\")\n",
        "    # assistant = initialize_assistant()\n",
        "    assistant_id = 'asst_H37be609KUxWRUur5uMu0WyC'\n",
        "\n",
        "    if \"thread_id\" not in st.session_state:\n",
        "        thread = client.beta.threads.create()\n",
        "        st.session_state.thread_id = thread.id\n",
        "\n",
        "    user_input = st.text_area(\"Ask a question:\", height=100)\n",
        "\n",
        "    if st.button(\"Get Response\"):\n",
        "        message = client.beta.threads.messages.create(\n",
        "            thread_id=st.session_state.thread_id,\n",
        "            role=\"user\",\n",
        "            content=user_input\n",
        "        )\n",
        "\n",
        "        run = client.beta.threads.runs.create(\n",
        "            thread_id=st.session_state.thread_id,\n",
        "            assistant_id=assistant_id\n",
        "        )\n",
        "\n",
        "        while run.status in [\"queued\", \"in_progress\"]:\n",
        "            run = client.beta.threads.runs.retrieve(\n",
        "                thread_id=st.session_state.thread_id,\n",
        "                run_id=run.id\n",
        "            )\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        messages = client.beta.threads.messages.list(thread_id=st.session_state.thread_id)\n",
        "        st.text_area(\"Response:\", value=messages.data[0].content[0].text.value, height=300, disabled=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dnix3TzG0AtU"
      },
      "outputs": [],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ecxyZmhq0BL7"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py & sleep 3 && npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH8jGZQX0FsL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
